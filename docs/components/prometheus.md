# Prometheus

The **Prometheus** service is the central **time-series database (TSDB)** for the entire platform. It acts as the high-performance data engine that powers the live plotting features in the main frontend application. Its role is to continuously collect, store, and serve the historical metrics generated by the unified data pipeline.

- **Technology:** Prometheus (via `prom/prometheus` Docker image)
- **Port:** `9090` (for its API and web UI)

## Key Responsibilities

- **Actively Scrapes Metrics:** Prometheus is configured to poll (or "scrape") the `/metrics` endpoint of the **[Virtual Data Fabric](components/virtual-data-fabric.md)** service every second. This high-frequency collection ensures that the data available for plotting is always up-to-date.
- **Stores Data with Rich Context:** Each piece of data is stored not just with a timestamp and a value, but also with a set of descriptive labels (e.g., `building`, `floor`, `room`) that were attached by the VDF.
- **Serves Queried Data:** It exposes a powerful query API that is used by two downstream services:
  1.  **[Plotting Service](components/service-ecosystem/plotting-service.md) (Primary Consumer):** Provides the data needed for the frontend's live plots.
  2.  **[Grafana](components/grafana.md) (Secondary Consumer):** Enables ad-hoc analysis and custom dashboard creation.

## The Scraping and Storage Workflow

The function of Prometheus is simple but critical. It operates in a continuous pull-based cycle:

1.  Every second, Prometheus sends a request to `http://virtual-data-fabric:8000/metrics`.
2.  The VDF responds with the latest values for all the sensors it is monitoring.
3.  Prometheus parses this response, ingests the metrics, and stores them efficiently on its local disk within the container.
4.  This stored, labeled data is now instantly available to be queried by other services.

### The Power of Labels: Enabling Filtered Queries

The effectiveness of this entire system hinges on the rich labels attached to each metric by the VDF. These labels are the keys that unlock powerful, filtered queries.

When the VDF exposes a metric, it looks like this:
`iot_sensor_value{building="my_smart_office",floor="floor_1",room="conference_room",thing_type="temperature"} 22.5`

These labels (`floor`, `room`, `thing_type`) allow the **[Plotting Service](components/service-ecosystem/plotting-service.md)** to ask very specific questions, such as:

- "Give me all the metrics for the `conference_room`."
- "Give me all the metrics on `floor_1`."

Without these labels, filtering data would be impossible. This demonstrates how the VDF and Prometheus are designed to work together as part of a cohesive, orchestrated system.

---

## System Dependencies

The `prometheus` service has one critical operational dependency.

!> **Critical Dependency:** The **[Virtual Data Fabric](components/virtual-data-fabric.md)** service must be running and serving metrics on its `/metrics` endpoint. If the VDF is down or has not yet been "built," Prometheus will still run, but it will be unable to scrape any data, rendering it ineffective.

---

## Configuration and Management

The Prometheus service is configured to be simple and focused on its primary task.

### `prometheus.yml`

The behavior of the service is controlled by a single configuration file, `prometheus.yml`, which is mounted into the container. Its configuration is minimal and defines two key things:

- **Scrape Interval:** Sets the polling frequency to one second (`scrape_interval: 1s`).
- **Scrape Target:** Defines the network address of the service to be scraped.
  ```yaml
  static_configs:
    - targets: ["virtual-data-fabric:8000"]
  ```

Aside from this file, the service runs with the default out-of-the-box configuration provided by the official Docker image.
